# PR-Review Nacharbeiten (Contract & Storage Follow-up)

Datum: 2025-11-08  
Autor: Codex (Teacher/Developer)  
Status: In Arbeit – Umsetzung geplant (Contract-Fixes), DX/Docker-Nacharbeiten folgen

## Hintergrund & Ziel
Im jüngsten Code-Review (`HEAD=ee034c3`) wurden zusätzliche Blocker identifiziert, die vor einem Merge adressiert werden müssen. Dieses Dokument sammelt die Analyse, formuliert User Stories und skizziert die Umsetzungsschritte gemäß unseren Prinzipien (Contract-First, TDD, KISS). Fokus liegt auf API-Vertragstreue, Sicherheit der Dev-Infra und Robustheit der Upload-Pipeline.

## Befunde aus dem Review
1. **[API] `analysis_json` verletzt den Vertrag für Submissions**  
   - Repo schreibt `analysis_json={"page_keys": [...]}` (ohne `schema`), während der OpenAPI-Vertrag ausschließlich `criteria.v1/v2` erlaubt.  
   - Impact: Client-Validatoren schlagen fehl; Lernende sehen inkonsistente Daten.

2. **[API] Neue Telemetrie-Felder werden nicht serialisiert**  
   - Vertrag garantiert `vision_attempts`, `vision_last_error`, `feedback_last_attempt_at`, `feedback_last_error`.  
   - DB-Abfragen liefern die Spalten, aber `_row_to_submission` entfernt sie → Frontend/SDKs bekommen unvollständige Antworten.

3. **[API] Upload-Proxy-Endpunkt fehlt im Vertrag**  
   - Bei `ENABLE_STORAGE_UPLOAD_PROXY=true` liefert `/upload-intents` eine URL auf `/api/learning/internal/upload-proxy`, obwohl dieser nicht im OpenAPI/BDD beschrieben ist.  
   - Impact: Kein getesteter Contract, Frontend-Dokumentation lückenhaft.

4. **[BUG] Proxy-Route blockiert Event Loop synchron**  
   - `internal_upload_proxy` ruft `requests.put` in einer `async`-Route auf → ganze Uvicorn-Worker werden während des Uploads blockiert.  
   - Impact: DoS-Potenzial bei großen Dateien; widerspricht KISS/Robustheit.

5. **[SEC] Ollama-Container exponiert Port 11434 öffentlich**  
   - Compose mappt `11434:11434` ohne Bind-Adresse/Firewall.  
   - Impact: Lokale LLM-Ausgabe inklusive PII ist im LAN erreichbar → DSGVO-Risiko.

6. **[DX/CONSISTENCY] Build/Docs-Feinschliff (Junior-Analyse)**  
   - Dockerfile enthält doppelte `pip install`-Schicht; `ollama` Version nicht gepinnt.  
   - `.env.example` sollte klaren Prod-Hinweis zu `AI_BACKEND=stub` enthalten.  
   - Whitespace-Leak in `.gitignore`.  
   - Migration „no raise on mismatch (jsonb)“ braucht Regressions-Test für idempotente Re-Updates.

## Plan (User Stories, Schritte, TDD)

### 1. Vertragstreues `analysis_json`
- **User Story**: Als Lernender möchte ich, dass jede Submission das dokumentierte `analysis_json`-Schema liefert, damit UI/SDKs zuverlässig rendern können.  
- **Entscheidung**: Option B (minimal): `analysis_json` bleibt bis Feedback `null`; `page_keys` werden nicht im Public Contract exponiert (nur intern persistiert).  
- **BDD**:  
  1. *Given* eine Lehrkraft markiert eine Submission als `extracted`, *When* die Submission über die API abgerufen wird, *Then* `analysis_json` ist `null` und enthält keine `page_keys`.  
  2. *Given* dieselbe Submission nach erfolgtem Feedback, *When* sie erneut geladen wird, *Then* `analysis_json` entspricht exakt dem dokumentierten Schema (`criteria.v1` oder `criteria.v2`).  
  3. *Given* ein nicht authentifizierter Nutzer, *When* er die Submission anfragt, *Then* antwortet die API mit `401` und ohne `analysis_json`-Information.  
- **OpenAPI-Entwurf**:  
  ```yaml
  Submission:
    type: object
    properties:
      analysis_json:
        nullable: true
        description: |
          `null` bis die Lehrkraft Feedback erteilt; anschließend eines der `criteria.*`
          Schemas. `page_keys` bleiben intern und sind kein Teil des öffentlichen Vertrags.
        oneOf:
          - type: 'null'
          - $ref: '#/components/schemas/CriteriaV1'
          - $ref: '#/components/schemas/CriteriaV2'
  ```
- **Migration-Entwurf**: Neue Spalte `internal_metadata jsonb default '{}'::jsonb` in `learning_submissions` (RLS-konform, nicht über API exponiert). `page_keys` werden dort persistiert und bleiben intern.  
- **Schritte**:  
  1. Repo/Serializer: Entfernen des Schreibens von `page_keys` in `analysis_json`; stattdessen Speicherung unter `internal_metadata` (jsonb).  
  2. OpenAPI/BDD: Klarstellen, dass bei `extracted` das Feld `analysis_json=null` ist.  
  3. Pytest: `test_learning_repo_mark_extracted` + Contract-Tests erwarten `analysis_json is None` im `extracted`-Status.  
- **Done-Definition**: `.venv/bin/pytest backend/tests/test_learning_api_contract.py -k analysis_json` grün; Contract-Linter bestätigt Schema.

### 2. Telemetrie-Felder liefern
- **User Story**: Als Produkt-Team brauche ich `vision_attempts` & Fehlerzeiten, um Lernenden sinnvolle Statusmeldungen anzuzeigen.  
- **Entscheidung**: Option A (öffentlich belassen): Alle vier Felder bleiben im Public Contract und werden ausgeliefert (mit Sanitization, wo relevant).  
- **BDD**:  
  1. *Given* eine Submission mit mindestens einem fehlgeschlagenen Vision-Lauf, *When* die API `/api/learning/submissions/{id}` aufgerufen wird, *Then* enthält die Antwort `vision_attempts` (>=1) und `vision_last_error` als sicheren Text (ohne Secrets, max. 256 Zeichen).  
  2. *Given* ein Worker hat einen Feedback-Lauf gestartet, *When* dieselbe Submission geladen wird, *Then* `feedback_last_attempt_at` ist ein ISO-Zeitstempel (`nullable:true`) und `feedback_last_error` ist höchstens 256 Zeichen.  
  3. *Given* ein Schüler ohne Berechtigung einen fremden Kurs abfragt, *When* er die Submission lädt, *Then* erhält er 403 und keine Telemetrie-Daten.  
- **Docs/UI**: 2025-11-08 – Abschnitt „Telemetry Surfaces“ in `docs/references/learning_ai.md` ergänzt; erläutert Student/Teacher-Ansicht und Sanitizer-Verhalten.  
- **Teacher/Worker Review**: 2025-11-08 – `_render_submission_telemetry` (backend/web/main.py:672ff) markiert Fehlertexte explizit als „nur Lehrkraft“ und nutzt dieselbe Sanitizer-Pipeline wie der Public Contract. Worker-Logs (`process_learning_submission_jobs.py:398-460`) loggen ausschließlich gekürzte Fehlermeldungen, bevor sie gespeichert/serialisiert werden. Kein weiterer Telemetriebedarf festgestellt.  
- **Repo/Unit Tests**: 2025-11-08 – Neues Testmodul `backend/tests/test_learning_repo_submission_mapping.py` deckt `_row_to_submission`-Pfad ab. Prüft, dass Pending-Submissions Analyse/Feedback verstecken, fehlende Attempts auf 0 fallen und Vision/Feedback-Fehler sanitisiert & ≤256 Zeichen bleiben.  
- **OpenAPI**:  
  ```yaml
  SubmissionTelemetry:
    type: object
    properties:
      vision_attempts:
        type: integer
        format: int32
        minimum: 0
        description: "Number of OCR/vision attempts for this submission"
      vision_last_error:
        type: string
        maxLength: 256
        nullable: true
        description: "Sanitized last error message visible to students"
      feedback_last_attempt_at:
        type: string
        format: date-time
        nullable: true
        description: "Timestamp of the last feedback generation attempt"
      feedback_last_error:
        type: string
        maxLength: 256
        nullable: true
        description: "Sanitized error text, teacher-facing"
  Submission:
    allOf:
      - $ref: '#/components/schemas/SubmissionTelemetry'
      - ... # restlich bestehende Properties
  ```
- **Schritte**:  
  1. Contract & Tests anpassen (API + UI + Repo), damit alle vier Felder verpflichtend vorhanden sind (`nullable` wo nötig).  
  2. Serializer/Repo auf vollständige SELECT-Ausgabe trimmen; Fehlertexte über `sanitize_error_message()` kürzen (<=256 Zeichen, gefährliche Tokens entfernen).  
  3. UI/Worker-Tests abgleichen; Edge-Case für `None` abdecken.  
- **Done**: JSON-Response enthält alle Felder, Snapshot-Tests aktualisiert.
- **Status 2025-11-08**: OpenAPI ergänzt (`SubmissionTelemetry`), Contract-Tests (`test_learning_api_contract.py`) schlagen nun fehl/grün → Repo liefert Felder, Sanitizer in `_row_to_submission`. SSR-UI testet Telemetrie-Rendering (`test_learning_ui_student_submissions.py::test_ui_history_fragment_renders_telemetry_block`).

### 3. Upload-Proxy dokumentieren & testen
- **User Story**: Als Frontend-Entwickler möchte ich einen dokumentierten Endpunkt für den Same-Origin-Proxy, damit ich Fehlfälle und CSRF-Anforderungen korrekt implementiere.  
- **Entscheidung**: Keine Änderung am derzeitigen Verhalten; insbesondere kein Rate‑Limiting hinzufügen.  
- **BDD**:  
  1. *Given* ein Schüler erhält einen Upload-Intent mit Proxy-URL, *When* er die Datei per Same-Origin PUT an `/api/learning/internal/upload-proxy?url=...` sendet, *Then* antwortet der Server mit `200` und JSON `{sha256,size_bytes}`.  
  2. *Given* derselbe Schüler versucht den Proxy ohne gültige `url`-Query oder mit Fremd-Host, *When* der Request verarbeitet wird, *Then* liefert die API `400 invalid_url_host`.  
  3. *Given* der Proxy-Flag `ENABLE_STORAGE_UPLOAD_PROXY` ist deaktiviert, *When* ein Schüler den Endpunkt aufruft, *Then* erhält er `404 not_found`.  
  4. *Given* das Upstream-Speicherziel antwortet mit 5xx, *When* der Proxy die Anfrage weiterleitet, *Then* liefert die API `502 bad_gateway` mit `detail` `upstream_error`.  
- **OpenAPI-Skizze**:  
  ```yaml
  /api/learning/internal/upload-proxy:
    put:
      tags: [Learning]
      summary: Proxy file upload to presigned storage (student-only)
      security: [ { cookieAuth: [] } ]
      parameters:
        - in: query
          name: url
          required: true
          schema: { type: string, format: uri }
          description: Presigned HTTPS URL returned by upload-intents endpoint (must match SUPABASE_URL host).
      requestBody:
        required: true
        content:
          application/octet-stream:
            schema: { type: string, format: binary }
      responses:
        '200': { description: Proxy succeeded, content: application/json => {sha256,size_bytes} }
        '400': { description: Bad request (missing_url | invalid_url | invalid_url_host | empty_body | size_exceeded) }
        '401': { description: Unauthenticated }
        '403': { description: Forbidden (CSRF) }
        '404': { description: Feature disabled (ENABLE_STORAGE_UPLOAD_PROXY=false) }
        '502': { description: Upstream error (proxy_failed | upstream_error) }
  ```
- **Schritte**:  
  1. OpenAPI erweitern (siehe Skizze) und Docstrings konsolidieren.  
  2. Neuer OpenAPI-Vertrags-Test (`backend/tests/test_openapi_learning_upload_proxy_contract.py`) verlangt Pfad, PUT, cookieAuth, binary payload & Fehlercodes.  
  3. Bestehende Proxy-Routentests weiterverwenden (kein Verhalten ändern).  
- **Status 2025-11-08**: OpenAPI-Pfad ergänzt (`api/openapi.yml`), Vertragstest hinzugefügt und ausgeführt (`.venv/bin/pytest backend/tests/test_openapi_learning_upload_proxy_contract.py -q`). Keine Code-Änderung an der Route nötig.  

### 4. Async-kompatible Proxy-Weiterleitung
- **User Story**: Als Betreiber möchte ich, dass Upload-Proxys keine Event-Loop-Blocker sind, damit parallele Lernende nicht hängen.  
- **Entscheidung**: Option B (Maintainer-Fokus): Verhalten unverändert lassen, aber technische Schulden abbauen → Proxy auf echte Async-Weiterleitung heben, keine Telemetrieänderung.  
- **BDD**:  
  1. *Given* ein Schüler PUT an `/api/learning/internal/upload-proxy` sendet, *When* die Weiterleitung via Async-Client erfolgt, *Then* blockiert kein Sync-Aufruf die Event Loop und die Antwort enthält `{sha256,size_bytes}`.  
  2. *Given* der Async-Forwarder wirft eine Exception, *When* der Proxy läuft, *Then* `502 bad_gateway` wird zurückgegeben und der Forwarder wurde awaited (keine unhandled warnings).  
  3. *Given* der Upstream antwortet mit 5xx, *When* der Async-Forwarder liefert `status_code>=300`, *Then* der Proxy antwortet mit 502 (wie bisher) und die Event Loop bleibt frei.  
  4. *Given* mehrere Uploads starten parallel, *When* ein Test den Proxy zweimal hintereinander awaited, *Then* beide Requests können ohne gegenseitiges Blockieren abgeschlossen werden (simulierter Async-Fake).  
- **Schritte**:  
  1. Utility `_async_forward_upload` in `routes.learning` schreiben (nutzt `httpx.AsyncClient`, optional Streaming).  
  2. Route `internal_upload_proxy` auf `await _async_forward_upload(...)` umstellen; Timeout + Headers übernehmen, Telemetrie-Hooks vorbereiten.  
  3. Tests: Bestehende Parity-/Fallback-Suites patchen, sodass sie den neuen Helper faken; zusätzlicher Test stellt sicher, dass der Helper awaited wird (`asyncio.Event`).  
  4. Dokumentation: Hinweis in `docs/references/learning_ai.md` oder Runbook, dass der Proxy Async ist und keine Soft-200 liefert.  
- **Done**: `.venv/bin/pytest backend/tests/test_learning_internal_proxy_prod_parity.py backend/tests/test_learning_upload_proxy_fallback.py -q` grün; keine `RuntimeWarning: coroutine was never awaited`.  
- **Status 2025-11-08**: `_async_forward_upload` implementiert (`backend/web/routes/learning.py`), Route nutzt httpx mit Timeout. Neue Tests (`test_upload_proxy_awaits_async_forwarder`, `test_upload_proxy_handles_parallel_requests`) sichern Await/Parallelität; Fallback-Test patched denselben Hook. Docs aktualisiert (`docs/references/learning_ai.md` Telemetry Surfaces).  

### 5. Ollama-Port absichern
- **User Story**: Als Datenschutzbeauftragter will ich, dass lokale KI-Dienste nicht unbeabsichtigt nach außen exponiert werden.  
- **Schritte**:  
  1. `docker-compose.yml`: Port-Bindung auf `127.0.0.1:11434` beschränken oder Port vollständig entfernen (nur interner Zugriff).  
  2. Dokumentation (`docs/references/compose_env.md`) aktualisieren – Hinweis auf SSH-Tunnel falls Remote-Zugriff nötig.  
  3. Optionaler Healthcheck via Make-Target `make test-ollama` anpassen (nutzt localhost).  
- **Entscheidung**: Nichts tun (keine Änderung an aktueller Compose‑Portbindung).  
- **Hinweis**: Sicherheitsbewertung bleibt bestehen; Wiedervorlage bei Prod‑Rollout.  
- **Status 2025-11-08**: Felix bestätigt, dass Prod/Home-Office-Server außerhalb des Schulnetzes läuft und den offenen Port bewusst nutzt. Option „nichts tun“ bleibt bestehen; erneute Bewertung bei späterem Deploy in fremden Netzen.  

### 6. DX/Consistency-Nacharbeiten (aus Junior-Analyse)
- **User Story**: Als Dev möchte ich deterministische Builds, saubere Beispiel-ENV und minimale Diffs, um Onboarding und CI stabil zu halten.  
- **Schritte**:  
  1. Dockerfile: Doppelte `pip install`-Schicht konsolidieren; `ollama`-Client optional pinnen (abhängig von CI‑Stabilität).  
  2. `.env.example`: Deutlicher Prod-Hinweis bei `AI_BACKEND=stub`.  
  3. `.gitignore`: überflüssige Whitespace-Zeile entfernen.  
  4. Tests: Neuer Case für „update_completed(jsonb) ist idempotent“ ergänzt (SQL + pytest).  
- **Done**: CI-Build zeigt reduzierte Layer; Linter/whitespace sauber; neuer Test schützt Idempotenz.
- **Status 2025-11-08**: Dockerfile aufgeräumt – nur noch ein `pip install -r requirements.txt`, keine Doppel-Installation. `ollama` bleibt via requirements (`ollama==0.3.0`) gepinnt.  
- **Status 2025-11-08**: `.env.example` warnt jetzt explizit, dass `AI_BACKEND=stub` in Prod verboten ist; `.gitignore` enthält keine Whitespace-Leaks mehr.  
- **Status 2025-11-08**: Neuer Regressionstest `backend/tests/test_learning_worker_security.py::test_learning_worker_update_completed_jsonb_is_idempotent` schützt den JSONB-Helfer vor Regressions (Befehl: `.venv/bin/pytest backend/tests/test_learning_worker_security.py -k jsonb -q`).  

## Tests & Verifikation
- Contract: `.venv/bin/pytest backend/tests/test_learning_api_contract.py -k submissions`  
- Proxy: `.venv/bin/pytest backend/tests/test_learning_internal_proxy_prod_parity.py backend/tests/test_learning_upload_proxy_fallback.py`  
- Telemetrie/UI: `.venv/bin/pytest backend/tests/test_learning_ui_student_submissions.py -k vision_attempts`  
- Repo: `.venv/bin/pytest backend/tests/test_learning_repo_mark_extracted.py backend/tests/test_learning_pdf_preprocessing_usecase.py`  
- Compose/Security: `docker compose ps` → kein offener 0.0.0.0:11434, manueller Curl-Test.
 - Docker/DX: Image-Build reproduzierbar, keine doppelte Layer-Installation; `.env.example`-Lint ok.  
 - SQL/Idempotenz: Neuer Test „completed→completed (jsonb)“ grün.

## Offene Fragen
1. —  
2. —  
3. —  

*(Bitte Antworten/Änderungen hier ergänzen, bevor die Umsetzung startet.)*

---

## Anhang: Punkte aus Junior-Analyse (integriert)
- [SEC] Pin für `ollama`-Client im Docker-Image; doppelte Install-Schicht entfernen (siehe Plan 6).  
- [DOC] Neue ENV-Variablen in `docs/references/*` dokumentieren.  
- [TEST] Idempotenz-Test für JSONB-Completed-Updates (siehe Plan 6).  
- [NICE] Multi-stage Build und `set -euo pipefail` für Makefile prüfen (kein Blocker).
