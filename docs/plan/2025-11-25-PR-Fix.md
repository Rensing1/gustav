# Plan: PR-Fixes für Backup & Learning Worker (2025-11-25)

## Ziel
- Review-Funde dokumentieren und Fix-Pfade festhalten, bevor die Korrekturen umgesetzt werden.

## Kontext
- Review auf HEAD 59ad06d, Fokus auf neues Backup-Skript und parallelen Learning-Worker.
- Sandbox: danger-full-access; TDD/TCR gelten weiter.

## Befunde (aus Review)
- SEC: `scripts/backup_daily.py` zeigt DB-Creds sowohl im `pg_dump`-Aufruf (Prozessliste) als auch in stderr → Secrets-Leak.
- BUG: Learning-Worker committet Leasing, bevor Verarbeitung fertig ist; bei Crash bleibt Job „leased“ bis Lease-Timeout, bei Laufzeit > Lease droht Doppelverarbeitung.
- SHOULD: `pg_dump` läuft ohne Timeout → potenziell hängender Cron-Run.
- SHOULD: Backup streamt Dumps komplett ins RAM (stdout→gzip) → OOM-Risiko bei großen DBs.
- TEST: Backup-Tests decken Fehlerpfade (pg_dump-Fehler, fehlender Storage-Root, Manifest-Status „failed“) noch nicht gezielt ab, obwohl sie im ursprünglichen Backup-Plan beschrieben sind.
- CONSISTENCY: Backup-DSN folgt nicht der im Backup-Plan dokumentierten Präferenz (`SESSION_DATABASE_URL` → Fallback `DATABASE_URL`), sondern nutzt `BACKUP_DATABASE_URL`/`DATABASE_URL` ohne klare Reihenfolge.
- CONSISTENCY: Manifest/Status wird nur bei Erfolg geschrieben; fehlgeschlagene Läufe hinterlassen kein Artefakt mit `status="failed"` für Operatoren.
- BUG/CONFIG: `WORKER_CONCURRENCY` ist nach oben unbeschränkt und nirgends dokumentiert; Fehlkonfiguration kann DB/AI-Backend überlasten.

## Fix-Ideen
- Backup: Passwort via `PGPASSWORD`/`pgpassfile` statt DSN im Kommando; stderr maskieren (host/db ohne Passwort); Timeout beim Subprozess (z. B. 300s + Kill); Dump-Output direkt zu gzip streamen (Popen + pipe) statt im RAM puffern.
- Worker: Leasing/Verarbeitung koppeln: entweder (a) Verarbeitung im selben Conn/Tx, Lease bleibt bis Commit; oder (b) bei Thread-Pfad Lease verlängern/aktiv halten und auf Fehler/Timeout „unleasen“, damit weder Doppelverarbeitung noch hängende Leases entstehen.
- Backup/DSN: DSN-Auswahl an Backup-Plan angleichen (`SESSION_DATABASE_URL` bevorzugen, dann `DATABASE_URL`, optional explizites `BACKUP_DATABASE_URL`), dabei Secrets nie in Logs/Dokumentation schreiben.
- Backup/Manifest: Manifest immer schreiben (ok/failed) und nur nicht-sensitive Metadaten (Timestamp, Artefakt-Namen, Exit-Codes) aufnehmen, damit Operatoren Teilerfolge nachvollziehen können.
- Tests: Zusätzliche Pytest-Cases für pg_dump-Fehler, fehlenden Storage-Root und fehlschlagende Läufe mit `status="failed"` ergänzen.
- Worker/Config: `WORKER_CONCURRENCY` nach oben begrenzen (z. B. max. 4), Default beibehalten (1) und ENV/Dokumentation (`.env.example`, Runbook) um diese Einstellung erweitern.
- Doku/Backup: Runbook und Compose-Setup synchronisieren (bevorzugter Weg: `backup-cron`-Service mit klar dokumentierten ENVs), alternative manuelle Cron-Zeile explizit als Option kennzeichnen.

## Tests/Verifikation
- `backend/tests/test_backup_daily.py` (Happy Path + fehlende ENV) erneut laufen.
- Learning-Worker Suite (`backend/tests/test_learning_worker_jobs.py`) mit Fokus auf Concurrency + Cache.
- Evtl. neuen Test für Leasing-Rollback hinzufügen.

## Offene Punkte
- Klären, ob Nonce/State/CSRF relevant für Backup-Logs (aktuell nein).
- Timeout-Werte mit Ops abstimmen (Default 300s ausreichend?).

## Umsetzung (Stand jetzt)
- Backup: DSN-Priorität (`SESSION_DATABASE_URL` → `BACKUP_DATABASE_URL` → `DATABASE_URL`), `pg_dump` via PGPASSWORD + Timeout + Streaming; Manifest auch bei Fehlern (`status=failed`); Fehlertexte ohne Passwörter.
- Tests: Backup-Fehlerpfade + DSN-Priorität abgedeckt.
- Worker: Concurrency hart auf 4 gedeckelt, unerwartete Exceptions setzen Job zurück auf `queued` (kein Leasen-Hänger).
