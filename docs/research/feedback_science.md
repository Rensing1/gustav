# KI-gestütztes formatives Feedback für Schüler

## Kriterien für gutes Feedback im Bildungsbereich (schriftliche Aufgaben)

**Formative Feedback** wird klassisch definiert als Rückmeldung, die Lernenden gegeben wird, um ihr Denken oder Verhalten in Richtung Lernziele zu verbessern. In der Forschung wurden klare **Qualitätskriterien** für solches Feedback herausgearbeitet. So betont Shute (2008), dass formatives Feedback **mehrdimensional**, **nicht-wertend**, **unterstützend**, **zeitnah**, **spezifisch**, **glaubwürdig**, eher **selten/dosiert** und **authentisch** sein sollte. Statt einer bloßen Bewertung (z. B. „gut“ oder einer Note) soll es konkrete Informationen liefern, die dem Lernenden helfen, die Lücke zwischen aktuellem Stand und Lernziel zu schließen. Hattie und Timperley (2007) fassen dies in drei Kernfragen, die gutes Feedback beantworten sollte: *„Wo stehe ich?“* (Ist-Stand bezogen auf das Lernziel), *„Wie geht es voran?“* (Fortschritt und Qualität der bisherigen Leistung) und *„Wo geht es als Nächstes hin?“* (konkrete nächste Schritte zur Verbesserung). Effektives Feedback richtet sich also darauf, dem Schüler sein Leistungsniveau im Verhältnis zu den Anforderungen aufzuzeigen und Wege zur Verbesserung anzubieten.

Darüber hinaus unterscheiden Hattie & Timperley auch **Feedback-Ebenen**: Rückmeldungen zum **Aufgabenergebnis** (Task), zum **Prozess** der Aufgabenbearbeitung, zur **Selbstregulation** des Lernenden sowie zum **Selbst** (persönliches Lob). Untersuchungen zeigen, dass Feedback auf den ersten drei Ebenen (Aufgabe, Prozess, Selbstregulation) am wirkungsvollsten ist, weil es direkt mit dem Lernen zusammenhängt, während reines Lob der Person („Du bist schlau.“) wenig Lerneffekt hat. Persönliches Lob kann zwar ermutigend sein, trägt aber alleine kaum zur Verbesserung fachlicher Leistungen bei, **es sei denn**, es wird mit konkreten Hinweisen zum Inhalt verknüpft.

Die Pädagogin Susanne Narciss betont zudem die **Interaktivität und Selbstregulationsförderung** als Kriterium guten Feedbacks. In ihrem **ITF-Modell** (Interactive Tutoring Feedback) beschreibt sie, dass wirksames Feedback kein einseitiges „Transmission“ sein sollte, sondern einen Dialog mit dem Lernenden darstellt. Gute Feedbackstrategien umfassen demnach mehrere Schritte: Zuerst werden die **Bewertungskriterien und Qualitätsstandards** der Aufgabe transparent gemacht, damit der Schüler weiß, was eine gute Lösung ausmacht. Dann wird der Lernende angeleitet, **selbst seine Lösung einzuschätzen** (Selbsteinschätzung), um Diskrepanzen zwischen Eigenwahrnehmung und Soll-Zustand aufzudecken. Anschließend erhält er die **externe Rückmeldung** zum erreichten Niveau mit Bezug auf die Kriterien sowie seine Selbsteinschätzung (Abgleich Soll-Ist). Darauf aufbauend sollte Feedback den Schüler zur **Reflexion über Verbesserungsmöglichkeiten** anregen und bei Bedarf **Hinweise, Beispiele oder Fragen** geben, **wie** die Lücke zu schließen ist. Schließlich sollte der Schüler Gelegenheit bekommen, die Hinweise umzusetzen und **das eigene Produkt zu überarbeiten**, wobei Fortschritte sichtbar gemacht und Erfolge hervorgehoben werden. Zusammengefasst heißt das: Qualitativ hochwertiges Feedback im Bildungsbereich orientiert sich an klaren Kriterien, adressiert **konkret die Leistung am Lernziel**, fördert die **selbstständige Fehlererkennung** und zeigt **konstruktive nächste Schritte** auf – all dies in einer unterstützenden, dialogischen Weise.

## Merkmale wirksamen formativen Feedbacks

Um Feedback für Schüler *wirklich lernwirksam* zu gestalten, haben Studien eine Reihe zentraler **Merkmale** identifiziert. Im Folgenden sind einige wichtige Merkmale zusammengefasst:

* **Verständlich und spezifisch:** Wirksames Feedback ist klar formuliert und bezieht sich genau auf die Aufgabe. Vage oder unklare Rückmeldungen können frustrierend wirken und den Lernerfolg sogar behindern. Statt allgemeiner Kommentare (“Gut gemacht!”) sollte z. B. konkret benannt werden, **was** bereits gelungen ist und **was** noch verbessert werden kann. Eine klare Bezugnahme auf die Lernziele oder Bewertungsrubrik erhöht die Verständlichkeit und Nützlichkeit der Rückmeldung. Wichtig ist auch, dass der Schüler die Rückmeldung richtig **interpretiert** – hierauf wies Hattie hin: Feedback nützt nur, wenn der Lernende es versteht und annehmen kann. Daher sollte die Sprache altersgerecht und nachvollziehbar sein und bei Unklarheiten Raum für Nachfragen lassen.

* **Aufgabenbezogen statt personenbezogen:** Feedback sollte sich auf die Lösung/den Text und deren Eigenschaften beziehen, **nicht auf die Person** des Lernenden. Studien zeigen, dass Rückmeldungen, die spezifische Aspekte der Schülerleistung adressieren (z. B. *„Dein Aufsatz hat eine klare Einleitung, aber die Argumente könnten mit mehr Beispielen belegt werden.“*), viel effektiver sind als Urteile über den Schüler selbst. Persönliche Wertungen oder Vergleiche (z. B. mit anderen Schülern) sind zu vermeiden. Auch sollte man vorsichtig mit pauschalem Lob umgehen: **Lob auf der Sachebene** (*„Deine Schlussfolgerung ist logisch und verständlich“*) kann motivieren, wohingegen reines Lob der Person (*„Du bist ein guter Schreiber“*) wenig Lerneffekt hat, wenn es keine weiteren Informationen enthält. Im schlimmsten Fall kann ständiges unspezifisches Lob sogar von den fachlichen Punkten ablenken. Daher gilt: **Konzentration auf Inhalt, Struktur und Vorgehen** der Schülerlösung.

* **Fehlerbezogen und hilfestellend:** Effektives Feedback liefert mehr als nur das Ergebnis *richtig/falsch* – es enthält **elaborierte Informationen** zu Fehlern und wie man sie beheben kann. Lernwirksam ist insbesondere sogenanntes **erklärendes Feedback**, das *Was*, *Warum* und *Wie* eines Problems beleuchtet. Anstatt nur die Korrektheit zu bestätigen, sollte das Feedback z. B. Hinweise geben: *„Der Lösungsansatz ist richtig, aber ein Rechenschritt ist fehlerhaft – prüfe noch einmal die Addition im zweiten Absatz.“* oder *„Deine Interpretation greift einen wichtigen Aspekt heraus (Was), aber erläutere noch, **warum** dieser Aspekt bedeutend ist.“* Solche inhaltlichen Erläuterungen fördern das Verständnis und haben deutlich positivere Lerneffekte als Feedback, das lediglich die richtige Lösung präsentiert. Wichtig dabei ist auch, die Menge der Information **dosiert** zu geben – in zu großen “Portionen” kann Feedback überfordernd sein. Besser ist eine schrittweise Rückmeldung (ggf. mehrere Feedback-Zyklen), damit der Schüler die Hinweise verarbeiten und selbst anwenden kann, ohne kognitiv überlastet zu werden.

* **Zeitnah, aber angemessen dosiert:** Die **Timing**-Frage ist entscheidend. Idealerweise erhalten Schüler möglichst zeitnah eine Rückmeldung, solange die Aufgabe noch frisch im Gedächtnis ist – unmittelbares Feedback kann gerade bei Anfängern das Lernen verbessern. Allerdings sollte Feedback nicht *dauernd* und bei jedem kleinen Schritt erfolgen; zu häufiges Eingreifen kann die **Selbstständigkeit** hemmen. Shute empfiehlt, formative Rückmeldungen eher **in Maßen** einzusetzen (Stichwort „infrequent“) – also wichtiges Feedback geben, wo nötig, aber nicht jeden Handgriff kommentieren. Die optimale Zeit und Frequenz hängt auch vom Lernstand ab: Fortgeschrittene kommen manchmal besser mit **verzögertem Feedback** zurecht, weil sie Zeit zum selbstständigen Nachdenken brauchen, während schwächere Schüler von sofortiger Korrektur und Hilfestellung profitieren können. Generell gilt: **sofortiges Feedback** ist v.a. bei Übungs- und Einstiegsaufgaben hilfreich, während **reflektierendes Feedback** nach einer eigenen Lösungsphase bei komplexen Aufgaben sinnvoll sein kann. In jedem Fall sollte das Feedback noch **rechtzeitig** kommen, damit der Schüler die Chance hat, Korrekturen vorzunehmen oder Gelerntes zeitnah anzuwenden.

* **Unterstützende, motivierende Tonalität:** Die Sprache des Feedbacks sollte ermutigend und respektvoll sein. Ein *wirkungsvolles formatives Feedback* schafft eine **positive Fehlerkultur** – Fehler werden als normaler Teil des Lernprozesses dargestellt, nicht als persönliches Versagen. So kann man im Feedback betonen, dass **Anstrengung** und **strategische Verbesserungen** zum Erfolg führen (*„Du hast bereits viel Aufwand investiert – mit einem zusätzlichen Beispiel könntest Du Deine Argumentation noch überzeugender machen.“*). Forschung zeigt, dass solch **lernorientiertes Feedback**, das die Botschaft vermittelt *„Aus Fehlern kannst du lernen und dich verbessern“*, die Motivation steigert. Explizit sollte vermittelt werden, *was* der Schüler durch Änderungen gewinnen kann. Negativ formulierte oder herabsetzende Kommentare sind unbedingt zu vermeiden – Kritik sollte *sachlich* bleiben und immer mit konstruktiven Verbesserungstipps einhergehen. Ein **motivationaler Aspekt** ist auch, **Erfolge hervorzuheben**: Damit ist kein oberflächliches Lob gemeint, sondern das Anerkennen konkreter Fortschritte (*„Deine zweite Version zeigt schon eine klarere Struktur – super, dass Du das Feedback zur Gliederung umgesetzt hast!“*). Solche Elemente erhalten die **Lernfreude** und geben dem Schüler Selbstvertrauen, weiter an der Aufgabe zu arbeiten. Insgesamt wirkt Feedback am besten in einer **unterstützenden Atmosphäre**, die fordert, aber nicht überfordert, und in der der Ton dem Schüler signalisiert: *„Ich als dein Lernbegleiter glaube daran, dass du das schaffen kannst, und gebe dir Tipps, wie.“*

Zusammengefasst zeichnet sich wirksames formatives Feedback durch **Inhaltliche Präzision**, **Fehlerdiagnose mit Hinweisen**, **timinggerechte Rückmeldung** und eine **ermutigende Sprache** aus. Es orientiert sich am Lernziel, gibt klar verständliche **Verbesserungsvorschläge** und fördert die **Eigenaktivität** des Schülers, anstatt ihn nur zu bewerten. Diese Merkmale bilden die Leitplanken für die Entwicklung einer Feedbackfunktion, die von Schülern als hilfreich empfunden wird und tatsächlich deren Lernen voranbringt.

## KI-basiertes Feedback mit großen Sprachmodellen (LLMs) gestalten

Angesichts dieser pädagogischen Anforderungen stellt sich die Frage, **wie KI-Systeme – insbesondere große Sprachmodelle wie GPT – so instruiert werden können, dass sie solches lernwirksames Feedback erzeugen**. Moderne Sprachmodelle können bereits kohärente Texte generieren und haben in ersten Studien gezeigt, dass sie prinzipiell hilfreiches Feedback formulieren können. Damit ein LLM jedoch pädagogisch sinnvolle Rückmeldungen gibt, ist **Prompt-Design (Prompting)** und eine geeignete Modell-Konfiguration entscheidend. Folgende Ansätze aus aktuellen Forschungsergebnissen und Experimenten haben sich als vielversprechend erwiesen:

* **Rollen- bzw. Persona-Prompting:** Dem KI-Modell wird im Prompt eine Rolle zugewiesen, die es bei der Antwort einnehmen soll. Beispielsweise kann man das LLM instruieren: *„Stell dir vor, du bist ein geduldiger Nachhilfelehrer, der einen Schülerfeedback zu dessen Aufsatz geben soll…“*. Tatsächlich wurde in Experimenten mit verschiedenen *Persona Patterns* beobachtet, dass dies den Stil und Fokus des Outputs positiv beeinflusst. So führt etwa die Persona *„Lehrassistent(in) einer Mittelstufe“* dazu, dass das Modell automatisch in einem schülergerechten, erklärenden Ton schreibt. Die KI „weiß“ dann implizit, dass von ihr **pädagogisch hilfreiche** Kommentare erwartet werden und nicht z. B. eine strenge Bewertung aus Prüfersicht. Persona-Prompting formt also den Kontext der Ausgabe und kann das Feedback zugänglicher und schülerorientierter machen.

* **Klare Kriterien und Rubrics im Prompt bereitstellen:** Ein sehr effektiver Ansatz ist, dem Modell **vorab die Bewertungsmaßstäbe bzw. eine Rubrik** zu geben, nach der es das Schülerprodukt beurteilen und Feedback generieren soll. Studien zeigen, dass **inhaltliche Rubrics als Prompt** die Leistung von GPT-basierten Systemen erheblich verbessern können. In einem Experiment erreichte ein GPT-4-basiertes Modell durch Vorgabe einer konzeptbasierten Bewertungsskala (Rubric) eine deutlich höhere Übereinstimmung mit menschlicher Beurteilung und generierte qualitativ besseres Feedback, als wenn man es nur mit Beispielen fütterte. Die Rubrik fungiert quasi als explizite Anleitung: Das Modell „weiß“, auf welche Aspekte (z. B. Argumentation, Rechtschreibung, Struktur, Kreativität etc.) es achten soll, und kann sein Feedback daran ausrichten. Ein Beispiel-Prompt könnte lauten: *„Bewerte den Aufsatz nach folgenden Kriterien: 1) Inhaltliche Richtigkeit, 2) Argumentative Struktur, 3) Sprachlicher Ausdruck,... Gib dem Schüler zu jedem Kriterium konstruktives Feedback.“* – Solche **strukturierenden Prompts** erhöhen die Wahrscheinlichkeit, dass das Feedback **vollständig und ausbalanciert** ausfällt, anstatt zufällig nur einzelne Punkte herauszugreifen. Wichtig ist hierbei, dass das Modell ausreichend Kontext hat: also sowohl die **Schülerantwort** als auch die **Aufgabenstellung** und die **Kriterien** geliefert bekommt, um fundiertes Feedback zu erzeugen.

* **Few-Shot-Learning mit Beispielen:** Alternativ oder ergänzend können **Beispiellösungen mit gewünschtem Feedback** dem Prompt hinzugefügt werden (In-Context Learning). Man könnte etwa ein Beispiel-Dialog voranstellen: *„Schülerantwort X… – Feedback des Tutors: …“* und dann die neue Schülerantwort folgen lassen. Dies zeigt dem Modell, welchen Stil und welche Detaillierung das Feedback haben soll. Solche **Beispiel-Prompts** können die Qualität verbessern, besonders wenn man unterschiedliche Qualitätsspannen demonstriert (z. B. Beispiel einer sehr guten und einer schwachen Lösung samt jeweiligem Feedback). Allerdings ist der Prompt-Kontext begrenzt (maximale Tokenlänge), sodass nicht beliebig viele Beispiele eingebunden werden können. Interessanterweise berichten aktuelle Untersuchungen, dass eine gut ausgearbeitete **Rubrik-Vorgabe häufig sogar effektiver ist als mehrere Beispiele**. Die Kombination beider Methoden – also ein oder zwei Beispieldurchläufe *plus* eine explizite Kriterienliste – kann jedoch auch genutzt werden, um dem LLM sowohl den Rahmen als auch den gewünschten Ton vorzugeben.

* **Chain-of-Thought und mehrstufige Instruktionen:** Ein weiterer Ansatz ist, das LLM schrittweise denken zu lassen, bevor es das finale Feedback formuliert. Man spricht von **„Chain-of-Thought“ (Gedankenkette)**-Prompting. Konkret kann man das Modell anweisen: *„Denke Schritt für Schritt: Analysiere zunächst den Text nach den Kriterien, notiere Dir deine Bewertung, **dann** formuliere das Feedback.“* In Experimenten wurde z. B. getestet, erst einen **Score** oder eine Analyse generieren zu lassen und danach das eigentliche Feedback. Eine Variante ist *„detailed CoT“*, bei der das Modell explizit aufgefordert wird, **mit Hilfe einer Rubrik alle Qualitätsaspekte durchzugehen**, bevor es das Feedback schreibt. Diese Methode soll sicherstellen, dass das KI-Modell **nichts Wesentliches übersieht** und sein Feedback logisch begründet. Zwar denken Sprachmodelle nicht wirklich wie Menschen, aber das Einfügen von *„Lass uns Schritt für Schritt überlegen…“* im Prompt kann dazu führen, dass die Ausgabe strukturierter und nachvollziehbarer wird. Beispielsweise könnte das Modell intern erst jeden Kriterienpunkt bewerten (z. B. Inhalt: gut – Begründung XY; Struktur: mittel – Begründung …) und daraus anschließend einen Fließtext als Schüler-Feedback generieren. Erste Befunde deuten darauf hin, dass **Chain-of-Thought-Prompting** die Tiefe der Analyse erhöhen kann – allerdings muss man dabei die Länge der Ausgabe im Blick behalten und ggf. die Anweisungen knapp halten.

* **Stilvorgaben und Sprache im Prompt:** Neben inhaltlichen Instruktionen kann man die **sprachliche Tonalität** des Feedbacks durch das Prompt steuern. Etwa könnte man hinzufügen: *„Antworte in einer freundlichen, ermutigenden Sprache auf dem Niveau eines 8.-Klässlers.“* oder *„Vermeide Fachjargon und formuliere deine Tipps positiv und motivierend.“* Da heutige große Sprachmodelle oft bereits darauf trainiert sind, höflich und hilfreich zu antworten, werden solche Vorgaben meist befolgt. Es ist aber sinnvoll, wichtige Punkte explizit zu erwähnen – z. B. *„Gib keine direkten Lösungen vor, sondern stelle Fragen, die den Schüler zur Lösung führen.“* (eine Strategie, die z. B. Khan Academy’s KI-Tutor verfolgt). Generell sollte das Prompt alle relevanten Leitplanken, die wir aus der Feedbackforschung kennen, an das Modell kommunizieren. Ein Beispiel für ein umfassendes Prompt für einen Textfeedback könnte sein:

  *„Du bist ein Tutor. Beurteile den folgenden Schülertext und gib ein schriftliches Feedback. Orientiere dich an diesen Kriterien: Inhaltliche Korrektheit, Verständlichkeit der Argumentation, Grammatik/Rechtschreibung. Hebe zunächst Positives hervor, zeige dann **konkret** Verbesserungsmöglichkeiten auf. Sprich den Schüler direkt und ermutigend an. Vermeide Wertungen wie ‚schlecht‘, sondern zeige lieber, wie es besser geht. Schülertext: ...“*.

  Ein so detailliertes Prompt erhöht die Chance, dass das KI-Feedback den gewünschten pädagogischen Qualitäten entspricht.

Zusammengefasst liefern die Forschung und Praxis folgende Kernempfehlungen, um LLMs zu **guten Feedbackgebern** zu machen: Das Modell mit den richtigen **Informationen und Rollen versehen**, klare **Erwartungen durch Kriterien/Rubrics** setzen, ggf. schrittweise Analysen (Chain-of-Thought) einleiten und auf einen **motivierenden Ton** hinweisen. Wichtig ist auch zu berücksichtigen, dass das LLM keine perfekte Wissensinstanz ist – es kann Fehler machen oder halluciniert falsche Fakten. Daher könnten technische Maßnahmen nötig sein (z. B. die KI mit Musterlösungen im Hintergrund abgleichen, um sachliche Fehler im Feedback zu vermeiden). Nichtsdestotrotz zeigen erste Studien, dass mit gutem Prompting **LLM-generiertes Feedback** inhaltlich **ausreichend genau** und didaktisch wertvoll sein kann. Entscheidend ist, dass wir beim Instruieren der KI die gleichen Prinzipien anwenden, die für menschliches Feedback gelten: klar, konstruktiv, lernzielorientiert und empathisch.

## Aktuelle Beispiele und Studien zu KI-Feedback im Schulkontext

In den letzten ein bis zwei Jahren hat es eine Reihe von Untersuchungen und Pilotprojekten gegeben, die zeigen, *wie KI-generiertes Feedback in schulischen Settings funktionieren kann*. Diese Beispiele umfassen verschiedene Fächer und Aufgabentypen – von Schreibaufgaben über argumentatives Diskutieren bis hin zu Programmierübungen:

* **Schreib- und Aufsatzaufgaben:** Eine wegweisende Studie wurde mit Oberstufenschülern durchgeführt, die im Fach Englisch argumentierende Aufsätze verfassten. In einem kontrollierten Experiment erhielten einige Schüler **LLM-basiertes Feedback** auf ihre Entwürfe, während eine Kontrollgruppe kein solches Feedback bekam. Die Ergebnisse waren positiv: Die Schüler mit KI-Feedback verbesserten ihre Texte in der Überarbeitung signifikant stärker als jene ohne Feedback. Zudem berichteten sie von **höherer Motivation**, weiter an ihren Aufsätzen zu feilen. Meyer et al. (2024) stellten fest, dass das KI-Feedback von den Schülern als *nützlich* wahrgenommen wurde – wichtigerweise sogar in der affektiven Dimension: Die Rückmeldungen der KI steigerten die **Zuversicht und positive Emotionen** der Lernenden im Umgang mit ihren Texten. Dies widerlegt teilweise die Befürchtung, dass nur menschliches Feedback motivierend wirken kann. Offenbar kann ein gut konstruiertes automatisches Feedback den Schülern das Gefühl vermitteln, *„da ist jemand/etwas, das auf meine Arbeit reagiert“*, was als Belohnung empfunden wird und zum Dranbleiben ermuntert. Praktisch bedeutete das in der Studie: Die KI gab innerhalb von Sekunden individuelles Feedback zu jedem Aufsatzentwurf, sodass die Jugendlichen **mehr Schleifen des Schreibprozesses** durchlaufen konnten (Entwurf → Feedback → Überarbeitung). Diese häufigeren Übungsmöglichkeiten führten zu besseren Endergebnissen, wie die verbesserten Schreibscores zeigten. Die Autoren betonen allerdings, dass Lehrkräfte die Schüler darauf vorbereiten sollten, KI-Feedback sinnvoll zu nutzen und auch kritisch zu hinterfragen – Stichwort *AI Literacy*. Dennoch liefern solche Studien ein Proof-of-Concept, dass **automatisiertes formatives Feedback beim Schreiben** in der Schule funktionieren kann und durchaus **lernförderlich** ist.

* **Argumentation und offene Aufgaben:** Neben reinen Schreibfähigkeiten wird KI-Feedback auch bei argumentativen oder erklärenden Aufgaben erprobt. Zum Beispiel im Fach Geschichte oder Politik, wo Schüler eine Position mit Gründen vertreten müssen, könnte ein LLM Feedback zur Stringenz der Argumentation geben. Eine Studie (Xiong et al., 2023) nutzte GPT-4, um Schüleraufsätze in Sozialkunde nach mehreren inhaltlichen Dimensionen zu bewerten und den Schülern Rückmeldung zu geben. Dabei stellte sich heraus, dass die KI mit einem detaillierten **Fach-Rubric** in der Lage war, **wissensintensive Essays** halbwegs zuverlässig zu beurteilen und Hinweise zu fehlenden Aspekten zu geben. Die Lehramtsstudie von Lai & Bui (2023) zeigte ebenfalls, dass KI-Feedback zur **Belegführung in Argumentationen** hilfreich sein kann, wenn das Modell z. B. aufgefordert wird, dem Schüler zu zeigen, wo noch Belege oder Beispiele gebraucht würden (die KI markierte Lücken in der Argumentation und schlug vor, welche Art von Beleg passen könnte). Solche Anwendungen stehen noch am Anfang, aber sie deuten an, dass **LLMs auch bei komplexeren inhaltlichen Aufgaben** Feedback geben können – vorausgesetzt, sie werden mit den richtigen fachlichen Kriterien gefüttert.

* **Mathematische Aufgaben und naturwissenschaftliche Fächer:** In MINT-Fächern ist Feedback oft unmittelbar (richtig/falsch), doch auch hier kann KI **erklärendes Feedback** bieten. Eine interessante Untersuchung von edukativen KI-Hinweisen in Mathematik ergab, dass **ChatGPT-generierte Hilfestellungen** bei Algebra-Aufgaben ähnlich gute Lernergebnisse erzielten wie menschliche Tutorenhinweise. Konkret wurden Schülern, die an einer Online-Lernumgebung Matheübungen lösten, bei Bedarf vom KI-Tutor gestufte Hinweise gegeben – beginnend mit einem kleinen Tip, dann einer größeren Hilfe. Die Analysen zeigten vergleichbare Fortschritte in den Testleistungen, was darauf hindeutet, dass KI-Hilfen kompetent genug waren, um die Schüler durch die Problemstellungen zu führen. Wichtig ist: Die KI lieferte hier nicht direkt die Lösung, sondern stellte Gegenfragen oder zeigte Teilschritte, ähnlich einem Socratischen Dialog. Diese Strategie – KI als fragender Coach – wird z. B. auch von Khan Academy’s **Khanmigo** verfolgt, der mit GPT-4 Mathematik-Aufgaben begleitet. Khanmigo ist so eingestellt, dass es **keine Lösungen verrät**, sondern mit den Schülern *„Schritt für Schritt näherungsweise“* die Lösung erarbeitet, indem es Fragen stellt und auf Fehlansätze hinweist. Erste Erfahrungsberichte aus Pilot-Klassenzimmern zeigen, dass Schüler diese Art von KI-gestütztem Feedback als Hilfestellung ähnlich nutzen wie die eines Mitschülers oder Tutors – sie bleiben aktiv im Lösungsprozess, haben aber einen ständigen Guide zur Hand. Diese Beispiele aus der Mathematik belegen, dass **formatives Feedback durch KI** nicht auf Texte beschränkt ist, sondern auch bei *lösungsorientierten Aufgaben* (Rechnungen, naturwissenschaftlichen Fragen etc.) greifen kann, wenn die KI entsprechend trainiert oder gepromptet ist.

* **Programmierung und technische Fächer:** Ein besonders spannendes Feld ist der Einsatz von KI-Feedback in der Programmierausbildung. Hier geht es oft um **Code-Lösungen**, bei denen automatisierte Tests zwar „richtig/falsch“ bewerten können, aber kein erklärendes Feedback liefern, *warum* ein Programm falsch ist oder wie man es verbessern könnte. Große Sprachmodelle, die Code verstehen, können diese Lücke füllen. In ersten Experimenten haben Forscher z. B. das Modell Claude auf Studenten-Code angesetzt und Rückmeldungen erzeugt, die Stil, Effizienz und Korrektheit des Codes betreffen. Ein Vorversuch mit Programmieraufgaben (Project Euler Probleme) zeigte, dass Studierende nach KI-Feedback ihren Code deutlich verbessern konnten – im Schnitt stieg die erreichte Punktzahl nach Revision um \~17 Punkte (auf einer 100-Punkte-Rubrik). Besonders auffällig waren Verbesserungen bei der **Algorithmuseffizienz und dem Abfangen von Randfällen**, was darauf hindeutet, dass die KI nicht nur offensichtliche Fehler, sondern auch *Optimierungspotenziale* aufzeigte. Aktuell läuft eine Folgestudie, in der echte Kursklassen entweder menschliches Feedback oder KI-basiertes Feedback auf Programmieraufgaben erhalten, um die Lernergebnisse und Akzeptanz zu vergleichen. Zwar liegen die endgültigen Ergebnisse noch aus, doch die bisherigen Daten deuten an, dass **LLM-Feedback im Programmierunterricht** praktikabel ist. Studierende schätzten insbesondere die **Schnelligkeit und Detailliertheit** der KI-Rückmeldungen: Der KI-Tutor verweist z. B. auf ineffiziente Codeteile und schlägt konkretere Alternativen vor (*„Dein Algorithmus hat eine Schleifenverschachtelung von O(n^2); du könntest versuchen, dies mit einem einzigen Durchlauf über die Daten zu lösen, etwa so: …“*). Solche Hinweise gehen über das hinaus, was ein herkömmlicher Unit-Test liefern könnte, und unterstützen einen *lernenden* Umgang mit Fehlern im Code. Natürlich muss man bei KI-generierten Code-Vorschlägen auch vorsichtig sein (Stichwort Korrektheit und unbekannte Fehlerquellen), aber mit sorgfältiger Prompt-Gestaltung (z. B. Hinweis an die KI, nur syntaktisch geprüften Code vorzuschlagen) lässt sich das Risiko minimieren.

Zusätzlich zu diesen Forschungsstudien gibt es bereits **praktische Erprobungen** von KI-Feedback-Systemen in Schulen und Hochschulen. Neben Khan Academy’s Khanmigo experimentieren mehrere EdTech-Plattformen mit GPT-4-basierten Tutoren in verschiedenen Fächern. Beispielsweise testet eine Schule ein KI-System, das **Aufsätze in Deutsch** auf Inhalt und Stil hin rückmeldet, oder es gibt Prototypen, die **Physik-Lernende** bei offenen Fragen durch KI-Kommentare unterstützen. Die bisherigen Rückmeldungen von Lehrkräften und Schülern sind gemischt, aber tendenziell positiv: Schüler schätzen die **Unmittelbarkeit** – sie können umgehend Feedback bekommen, anstatt Tage auf die Korrektur durch den Lehrer zu warten. Lehrer wiederum sehen entlastende Effekte, da Routine-Feedback (etwa bei Hausaufgaben) von der KI übernommen werden kann und sie sich auf tiefergehende Diskussionen konzentrieren können. Allerdings wird auch betont, dass die Rolle der Lehrperson weiterhin wichtig bleibt: Die KI kann viele Feedback-Aufgaben skalieren, **muss aber pädagogisch eingebettet** werden. Zum Beispiel sollten Lehrkräfte mit den Schülern besprechen, wie man KI-Feedback interpretiert, was man davon umsetzt und wo vielleicht Vorsicht geboten ist (etwa falls die KI mal falsche Ratschläge gibt).

**Fazit:** KI-gestütztes formatives Feedback ist auf dem Vormarsch und bereits in ersten Studien **erfolgreich erprobt** worden. Von **Texterörterungen** über **Argumentationsanalysen** bis hin zu **Programmieraufgaben** zeigen sich positive Effekte auf Lernen und Motivation, sofern die Rückmeldungen qualitativ den anerkannten Feedbackkriterien entsprechen. Diese Ergebnisse können direkt in die Gestaltung unserer geplanten Lernplattform einfließen. Theoretisch fundierte Prinzipien (Klarheit, Konstruktivität, Lernförderlichkeit) lassen sich mit den technischen Möglichkeiten der LLMs verbinden. Konkret bedeutet das: Wir werden unser Sprachmodell so prompten und konfigurieren, dass es **schülerzentriertes, elaboriertes Feedback** gibt – z. B. durch Eingabe von Aufgabenrubrics, Beispielantworten und erwünschtem Stil – und es in verschiedenen Fachdomänen anwenden. Die **Vision** ist eine Plattform, auf der Schüler in Mathe, Sprache, Informatik usw. nach jeder Aufgabe personalisierte, hilfreiche Rückmeldungen erhalten können, die sie motivieren und leiten, *ohne* dass stets ein Lehrer direkt danebenstehen muss. Die neuesten Forschungsergebnisse stimmen optimistisch, dass wir dieses Ziel erreichen können, solange wir die KI mit didaktischem Feinsinn einsetzen und ihre Outputs kontinuierlich evaluieren und verbessern. So wird aus der Theorie und Technologie letztlich eine praxisgerechte Feedback-Funktion, die Lernen in verschiedensten Fächern unterstützt.

**Quellen:** Die Ausführungen stützen sich auf pädagogische Feedback-Literatur (u.a. Shute 2008, Hattie & Timperley 2007, Narciss 2012) sowie aktuelle Studien zu KI-unterstütztem Feedback im Bildungsbereich. Diese Kombination aus Theorie und empirischen Befunden bildet die Grundlage für die Gestaltung einer KI-Feedbackfunktion, die *sowohl lernwirksam als auch technisch realisierbar* ist.
