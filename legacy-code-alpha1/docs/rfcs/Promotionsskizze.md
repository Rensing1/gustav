# Exposé zur Dissertation

**Titel:** _Die symbiotische Feedback‑Schleife: Eine Design‑Based‑Research‑Studie zur datengestützten Unterrichtsentwicklung durch die Koppelung von Schüler‑Interaktion und Lehrer‑Diagnostik in digitalen Lernumgebungen_

## 1 Problemstellung und Relevanz des Forschungsvorhabens

Die fortschreitende Digitalisierung des Bildungswesens schafft neue Möglichkeiten für datengestützte Lehr‑ und Lernprozesse. Insbesondere _Learning Analytics_ (LA) verspricht – durch die Erhebung, Analyse und Visualisierung von Daten aus digitalen Lernumgebungen – Lehrkräfte bei der formativen Beurteilung und individuellen Förderung von Lernenden zu unterstützen. Ein zentrales Instrument sind sogenannte _Learning‑Analytics‑Dashboards_ (LADs). Diese aggregieren Lernprozessdaten und bereiten sie für Lehrkräfte auf. Im Idealfall erhalten Lehrkräfte zeitnahe und detaillierte Einblicke in Lernstände und Schwierigkeiten der Lernenden und können ihren Unterricht adaptiver und effektiver gestalten. Systematische Übersichten heben jedoch hervor, dass viele LA‑Lösungen bisher ihr Potenzial nicht ausschöpfen. In einer umfangreichen Synthese von 38 Studien zu LADs fanden Kaliisa u. a., dass der Einsatz von Dashboards in den betrachteten Untersuchungen keine nachweisbare Verbesserung der Lernergebnisse zeigte und die Effekte auf Motivation und Lernverhalten gering waren (Kaliisa et al., 2023). Auch Masiello u. a. betonen in einer neueren Übersicht, dass Vorhersagen aus LA‑Systemen häufig _nicht klar in didaktisches Handeln übersetzt_ werden und die potenzialstarke Verbindung zu selbstreguliertem Lernen und Spielmechaniken noch kaum genutzt wird (Masiello et al., 2024). Dieses Problem wird in der Analytik‑Forschung als **„Last‑Mile‑Problem“** beschrieben – die kritische Lücke zwischen der Präsentation von Informationen und den darauf basierenden handlungsleitenden Entscheidungen der Anwender*innen.

Übertragen auf den schulischen Kontext bedeutet dies, dass die „letzte Meile“ – die erfolgreiche _Interpretation_ der Dashboard‑Daten und deren _Übersetzung_ in konkrete didaktische Maßnahmen – eine entscheidende, aber oft vernachlässigte Hürde darstellt. Viele technologiebasierte Innovationen scheitern an dieser Implementierungslücke, weil die kognitiven Prozesse, professionellen Routinen und subjektiven Deutungen der Lehrkräfte nicht ausreichend berücksichtigt werden. Die Forschung berichtet eine begrenzte empirische Evidenz für die Wirksamkeit von LADs: Eine systematische Übersicht fand keine Hinweise darauf, dass Dashboards Lernleistungen verbessern, und hob geringe Effekte bei Motivation und Einstellungen sowie methodische Schwächen vieler Studien hervor (Kaliisa et al., 2023). Hinzu kommt, dass die von den Systemen gelieferten Vorhersagen vielfach „nicht klar in pädagogische Handlungen übersetzt“ werden (Masiello et al., 2024). Komplementär wird der sogenannte _Feedback Gap_ beschrieben – die Diskrepanz zwischen dem Potenzial von Feedback und dessen tatsächlicher Nutzung. Iraj u. a. zeigen, dass Lehrkräfte oft keinen Einblick haben, ob und wie Lernende mit bereitgestelltem Feedback interagieren, und dass diese Lücke den Lernerfolg beeinträchtigt (Iraj et al., 2021).

Diese Befunde machen deutlich, dass die erfolgreiche Überbrückung der _letzten Meile_ eine zentrale Herausforderung darstellt. Das vorliegende Forschungsvorhaben adressiert exakt dieses Problem. Es postuliert, dass die Wirksamkeit eines LA(D)‑gestützten Systems von einer funktionierenden **symbiotischen Feedback‑Schleife** abhängt: Die Akzeptanz und sinnvolle Nutzung des Systems durch die Lernenden generiert aussagekräftige Daten für die Lehrkraft. Diese diagnostische Wahrnehmung motiviert die Lehrkraft wiederum, das Dashboard gezielt einzusetzen und den Unterricht anzupassen – was sich positiv auf das Lernen auswirken sollte. Die empirische Untersuchung dieser wechselseitigen Abhängigkeit stellt eine signifikante Forschungslücke dar und ist von hoher Relevanz für die Gestaltung zukünftiger Learning‑Analytics‑Anwendungen.

## 2 Theoretischer Hintergrund und Forschungsstand

Um das komplexe Zusammenspiel von Lernenden, Lehrenden und Technologie theoretisch zu fassen, stützt sich dieses Vorhaben auf drei zentrale Säulen: die Technologieakzeptanz der Lernenden, die Datenkompetenz der Lehrenden und die kognitive Belastung, die das System auf beide Gruppen ausübt.

### 2.1 Technologieakzeptanz als Gelingensbedingung

Das von Davis entwickelte _Technology Acceptance Model_ (TAM) gehört zu den etablierten Modellen zur Erklärung der Nutzung von Technologien. Es besagt, dass die Nutzungsintention von der wahrgenommenen Nützlichkeit (_perceived usefulness_) und der wahrgenommenen Benutzerfreundlichkeit (_perceived ease of use_) abhängig ist (Davis, 1989). PU beschreibt den Grad, zu dem eine Person glaubt, dass die Nutzung eines Systems ihre Leistung verbessert; PEOU den Grad, zu dem die Nutzung als frei von Aufwand empfunden wird. Im Kontext dieses Vorhabens ist TAM fundamental, weil die freiwillige und engagierte Nutzung der digitalen Lernumgebung durch die Lernenden Voraussetzung für die Generierung aussagekräftiger Daten ist. Das Modell wurde allerdings für _freiwillige_ Nutzungssituationen entwickelt. In schulischen Pflichtsettings – in denen Lernende ein System auf Anweisung der Lehrkraft nutzen müssen – verändern sich die Beziehungen zwischen Nützlichkeit, Benutzerfreundlichkeit und Nutzung. Brown u. a. zeigten, dass bei verpflichtend bereitgestellten Technologien andere Faktoren die Nutzung beeinflussen und die Vorhersagekraft traditioneller Akzeptanzmodelle abnimmt (Brown et al., 2002). Entsprechend erfordert die Interpretation von Akzeptanzdaten in Pflichtkontexten eine kritische Reflexion. Dieser Aspekt wird im vorliegenden Design durch die Triangulation mit objektiven Nutzungsdaten berücksichtigt (siehe Abschnitt 5).

### 2.2 Professionelle Kompetenz als Flaschenhals: Teacher Data Literacy

Selbst wenn eine hohe Akzeptanz auf Seiten der Lernenden eine reichhaltige Datengrundlage schafft, bleibt der Nutzen für den Unterricht aus, wenn die Lehrkraft nicht über die nötige professionelle Kompetenz verfügt, diese Daten zielführend zu nutzen. Diese Kompetenz wird unter dem Begriff _Teacher Data Literacy_ gefasst. Mandinach und Gummer definieren Datenkompetenz für Lehrkräfte als die Fähigkeit, Informationen in umsetzbares didaktisches Wissen zu verwandeln, indem verschiedenartige Daten gesammelt, analysiert und interpretiert werden, um daraus geeignete nächste Unterrichtsschritte abzuleiten (Mandinach & Gummer, 2016). Diese Definition hebt hervor, dass Lehrkräfte Daten aus unterschiedlichen Quellen integrieren und in pädagogische Entscheidungen überführen müssen. Studien zeigen, dass genau diese Kompetenz eine erhebliche Hürde darstellt. Michos u. a. berichten, dass zwar mehr als die Hälfte der befragten Lehrkräfte Zugang zu digitalen Daten hat, aber lediglich ein Drittel diese tatsächlich nutzt und nur rund ein Viertel sich sicher im Umgang mit Daten fühlt; das Vorhandensein von Technologie allein reicht also nicht aus (Michos et al., 2023). Papamitsiou u. a. zufolge umfasst Datenkompetenz nicht nur das Erfassen und Analysieren, sondern auch das Erkennen von Problemen, das Transformieren von Daten in Information, das Ableiten von Entscheidungen und die Evaluation der Ergebnisse (Papamitsiou et al., 2021). In der Praxis sind die Visualisierung und Interpretation von Lernverlaufsdaten häufig nicht ausreichend an die Expertise der Lehrkräfte angepasst. Pozdniakov u. a. weisen darauf hin, dass die Visualisierungskompetenzen der Lehrkräfte stark variieren und viele Dashboards diese Unterschiede ignorieren, was die Interpretation von Dashboards erschwert (Pozdniakov et al., 2024). Diese Befunde unterstreichen, dass die „letzte Meile“ oft daran scheitert, dass Lehrkräfte zwar mit Daten konfrontiert werden, ihnen jedoch das erforderliche Wissen, die passenden Werkzeuge oder die Ausbildung fehlen, um daraus konkrete Diagnosen und Handlungen abzuleiten. Dem Bedarf nach Fortbildungen und Unterstützungsangeboten wird in der Forschung zunehmend Aufmerksamkeit geschenkt (Ifenthaler & Olsen, 2020).

### 2.3 Kognitive Entlastung als Notwendigkeit: Cognitive Load Theory

Die _Cognitive Load Theory_ (CLT) bildet den dritten theoretischen Rahmen. Sie basiert auf der Annahme einer bestimmten kognitiven Architektur: Ein stark begrenztes Arbeitsgedächtnis steht einem nahezu unbegrenzten Langzeitgedächtnis gegenüber. Van Merriënboer und Sweller erläutern, dass das Arbeitsgedächtnis nur wenige Informationseinheiten gleichzeitig verarbeiten kann, während das Langzeitgedächtnis schematische Wissenseinheiten speichert, die die Belastung des Arbeitsgedächtnisses reduzieren (van Merriënboer & Sweller, 2005). Die CLT unterscheidet drei Formen kognitiver Belastung: die _intrinsische_ Last (bedingt durch die Komplexität des Lerngegenstands), die _extrinsische_ Last (verursacht durch die Darstellungsform und unnötige kognitive Prozesse) und die _germane_ Last (jene Anteile, die in Schemaerwerb und Lernen fließen). Extrinsische kognitive Last ist nach dieser Theorie überflüssig und kann durch Gestaltung reduziert werden, um mehr Kapazität für lernrelevante Prozesse zu schaffen (van Merriënboer & Sweller, 2005). Ein Ziel effektiven Instruktionsdesigns besteht darin, extrinsische Belastung zu minimieren, etwa durch klare Darstellungen, Integration verwandter Informationen oder Nutzung von visuellem statt rein verbalem Code. Die CLT ist in diesem Vorhaben in doppelter Hinsicht relevant: Sie gilt sowohl für die Gestaltung der Lernumgebung für Lernende als auch für das Lehrer‑Dashboard. Beide Komponenten müssen so konzipiert sein, dass sie die kognitiven Ressourcen der Nutzer*innen nicht unnötig belasten.

### 2.4 Synthese und Forschungslücke

Die drei theoretischen Säulen bedingen einander: Die Akzeptanz der digitalen Lernumgebung durch die Lernenden (TAM) ist Voraussetzung für die Generierung aussagekräftiger Nutzungsdaten. Die Interpretation dieser Daten zur Ableitung pädagogischer Maßnahmen erfordert eine hohe Datenkompetenz der Lehrkraft (Teacher Data Literacy). Diese Kompetenz kann jedoch nur wirksam greifen, wenn das diagnostische Werkzeug – das Lehrer‑Dashboard – so gestaltet ist, dass es die kognitive Belastung minimiert und eine effiziente Analyse ermöglicht (CLT).

Aktuelle Übersichtsarbeiten stützen die Annahme, dass die empirische Untersuchung der Koppelung dieser Komponenten eine Forschungslücke darstellt. Die in Learning‑Analytics‑Anwendungen gewonnenen Vorhersagen und Einsichten werden häufig nicht in didaktisches Handeln überführt (Masiello et al., 2024). Zudem zeigt die Auseinandersetzung mit dem Feedback Gap, dass Lehrkräfte oft keinen Einblick haben, ob und wie Lernende mit Feedback umgehen (Iraj et al., 2021). Die Synthese dieser Befunde unterstreicht, dass die Untersuchung der _dynamischen Koppelung_ der beiden „Hälften“ der Feedback‑Schleife (Schüler‑ und Lehrerseite) ein zentrales Desiderat der Bildungsforschung darstellt. Hier setzt das vorliegende Forschungsvorhaben an.

## 3 Forschungsvorhaben und zentrale Fragestellungen

Das Promotionsvorhaben fokussiert auf die Prozess‑ und Gelingensbedingungen der **symbiotischen Feedback‑Schleife** zwischen Schüler‑Interaktion und Lehrer‑Diagnostik. Eine KI‑gestützte Lernplattform fungiert als zentrales _Forschungsartefakt_. Die Entwicklung dieses Artefakts folgt der Methodologie der **Design‑Based Research (DBR)** und ist kein rein technischer Selbstzweck, sondern der Umsetzungsträger für theoretisch abgeleitete Hypothesen. In iterativen Zyklen werden hypothesengeleitete Gestaltungsprinzipien erprobt, um Erkenntnisse über eine funktionierende Feedback‑Schleife zu gewinnen. Jeder DBR‑Zyklus liefert nicht nur Befunde über die Nutzung, sondern generiert empirisch begründete Anforderungen für das Re‑Design des Artefakts.

Aus diesem Ansatz leiten sich folgende zentrale Forschungsfragen (FF) ab:

- **FF1 (Schülerperspektive):** Inwieweit akzeptieren die Lernenden die KI‑gestützte Lernumgebung im Hinblick auf deren wahrgenommene Nützlichkeit und Benutzerfreundlichkeit?
    
- **FF2 (Lehrerperspektive):** Wie und zu welchen Zwecken nutzt die Lehrkraft die im Dashboard visualisierten Daten, um diagnostische Urteile zu bilden und unterrichtliche Handlungen abzuleiten?
    
- **FF3 (Integrative Perspektive):** Wie gestaltet sich die Wechselwirkung zwischen der Akzeptanz auf Lernendenseite und der diagnostischen Datennutzung auf Lehrerseite? Welche Gelingensbedingungen und Barrieren für eine funktionierende symbiotische Feedback‑Schleife lassen sich identifizieren?
    

## 4 Methodisches Vorgehen und Forschungsdesign

### 4.1 Forschungsparadigma: Design‑Based Research

Als übergeordnetes Paradigma dient die **Design‑Based Research**. Dieser Ansatz stellt eine „systematische, aber flexible Methodologie“ dar, die darauf abzielt, Bildungspraktiken durch iterative Analyse, Design, Entwicklung und Implementierung zu verbessern (Wang & Hannafin, 2005). DBR wird in authentischen Kontexten durchgeführt und ermöglicht es, praktische Barrieren – wie jene der „letzten Meile“ – im Detail zu analysieren. Die gewonnenen Einsichten fließen unmittelbar in das Re‑Design der Intervention für den nächsten Zyklus ein. DBR verfolgt somit eine doppelte Zielsetzung: _praktische Lösungen_ zu entwickeln und zugleich _theoretische Erkenntnisse_ zu generieren (Wang & Hannafin, 2005).

### 4.2 Design der Pilotstudie: Konvergentes paralleles Mixed‑Methods‑Design

Innerhalb des DBR‑Rahmens wird für die Pilotstudie ein **konvergentes paralleles Mixed‑Methods‑Design** angewendet. Quantitative und qualitative Daten werden parallel erhoben, zunächst getrennt analysiert und anschließend zusammengeführt. Dieses Design erlaubt eine _Triangulation_ der Befunde, bei der sich die Stärken beider Methoden ergänzen und Ergebnisse wechselseitig bestätigen oder erklären (Creswell & Plano Clark, 2018). Das Ziel der Triangulation besteht darin, durch die Nutzung mehrerer Methoden und Datenquellen das Vertrauen in die Befunde zu stärken und ein breiteres Verständnis des untersuchten Phänomens zu erreichen (ATLAS.ti, 2024). Der parallele Ansatz ist dadurch gekennzeichnet, dass quantitative und qualitative Stränge gleichwertig sind und innerhalb eines kurzen Zeitrahmens erhoben werden (Simply Psychology, 2024). Die Integration der Daten erfolgt nach getrennten Analysen in einem gemeinsamen Schritt, häufig anhand sogenannter **Joint Displays** – tabellarischer Darstellungen, in denen vergleichbare Kategorien den Befunden aus beiden Datenquellen gegenübergestellt werden (Simply Psychology, 2024). Die Zusammenführung zielt darauf ab, **Meta‑Inferenzen** zu erzeugen: übergeordnete Schlussfolgerungen, die aus der Verbindung von qualitativen und quantitativen Ergebnissen hervorgehen und über das hinausgehen, was eine Einzelmethode leisten kann (Younas et al., 2025).

### 4.3 Datenerhebungsstränge im Pilotzyklus

#### 4.3.1 Schülerperspektive: Quantitative und qualitative Erfassung

- **Instrument 1 (quantitativ): Fragebogen zur Technologieakzeptanz.** Zur Messung der Akzeptanz der Lernumgebung wird ein für den deutschen Schulkontext entwickelter und validierter Fragebogen eingesetzt, der die Dimensionen wahrgenommene Nützlichkeit, wahrgenommene Einfachheit der Nutzung sowie Nutzungsintentionen in Bezug auf KI‑basierte Lernanwendungen erfasst (Mesenhöller & Böhme, 2024). Der Fragebogen ist speziell auf die Erfahrungswelt von Lernenden zugeschnitten und erlaubt eine differenzierte Erfassung ihrer Einstellungen.
    
- **Instrument 2 (objektive Daten): Automatische Nutzungsprotokolle.** Die digitale Lernplattform zeichnet Log‑Daten zum Lernverhalten der Lernenden auf. Im Pilotzyklus werden insbesondere Nutzungsfrequenzen, Verweildauer in Lerneinheiten, Bearbeitungszeiten pro Aufgabe und Interaktionsmuster (z. B. Nutzung von Hinweisen oder Abbruchquote) erfasst. Diese objektiven Verhaltensdaten dienen der Validierung der Selbstauskünfte im Fragebogen und erlauben Analysen zum Engagement der Lernenden.
    

#### 4.3.2 Lehrerperspektive: Qualitative Erfassung

- **Instrument 1: Semistrukturierte Leitfadeninterviews.** Mit der teilnehmenden Lehrkraft werden in verschiedenen Phasen der Studie Interviews geführt, die auf ihre Erfahrungen mit dem Dashboard, die mentalen Prozesse bei der Dateninterpretation und die daraus resultierenden Unterrichtsentscheidungen abzielen. Die halbstrukturierte Form ermöglicht es, unvorhergesehene Aspekte aufkommen zu lassen und dennoch Vergleichbarkeit zu wahren.
    
- **Instrument 2: Strukturiertes Forschungstagebuch.** Die Lehrkraft dokumentiert nach jeder relevanten Dashboard‑Nutzung Anlass, Schlüsselerkenntnisse, diagnostische Schlüsse und geplante Unterrichtsentscheidungen. Dieses Tagebuch liefert Daten zum tatsächlichen Nutzungsverhalten und fungiert zugleich als Reflexionsanreiz.
    
- **Qualitätssicherung durch einen Critical Friend.** Um Verzerrungen in der Datenauswertung zu minimieren, wird der Betreuer die Rolle eines „Critical Friend“ einnehmen. Ein Critical Friend ist ein Kollege, der aufmerksames Zuhören mit ehrlicher Rückmeldung kombiniert und den Forschenden bei der Überprüfung seiner Analysen unterstützt (Stenhouse zitiert nach McNiff, 2002). Diese Person hinterfragt Kategorienschemata und Interpretationen kritisch und hilft, blinde Flecken zu erkennen.
    

### 4.4 Datenintegration und Meta‑Inferenzen mittels Joint‑Display‑Analyse

Der entscheidende Schritt im konvergenten Design ist die **Integration** der quantitativen und qualitativen Daten. Statt die Ergebnisse beider Stränge isoliert nebeneinander zu stellen, werden sie in einer gemeinsamen Darstellung – einem Joint Display – miteinander verknüpft. In diesem Display werden vergleichbare Kategorien oder Themen den jeweiligen Befunden aus beiden Datenquellen gegenübergestellt. Divergenzen und Konvergenzen lassen sich so unmittelbar erkennen. Die systematische Gegenüberstellung führt zu **Meta‑Inferenzen** – übergreifenden Schlussfolgerungen, die ein tieferes Verständnis des Forschungsproblems ermöglichen (Younas et al., 2025). Ein Beispiel wäre: „Eine hohe subjektive Nützlichkeitseinschätzung geht nur dann mit hoher tatsächlicher Nutzungsintensität einher, wenn bestimmte Gelingensbedingungen (z. B. Gamification‑Elemente, unmittelbares Feedback) erfüllt sind.“ Solche Meta‑Schlüsse beantworten die Forschungsfragen und generieren neues Wissen über die Zusammenhänge im untersuchten System.

## 5 Limitationen, Risiken und Ausblick

- **Limitation des Akzeptanzmodells:** Die Anwendung eines Akzeptanzmodells wie TAM in einem Pflichtkontext erfordert eine kritische Reflexion. Brown u. a. betonen, dass in mandatierten Settings die Beziehungen des TAM verändert sind und externe Vorgaben eine zentrale Rolle spielen (Brown et al., 2002). Daher wird im Projekt großer Wert auf die Kombination subjektiver Akzeptanzmaße mit objektiven Nutzungsdaten gelegt.
    
- **Generalisierbarkeit:** Die Ergebnisse einer DBR‑Einzelfallstudie sind kontextspezifisch. Ziel ist die Entwicklung einer lokalen Theorie und von Gestaltungsprinzipien, die im spezifischen Umfeld Gültigkeit besitzen. Eine statistische Generalisierung auf andere Schulen ist nur begrenzt möglich; durch ausführliche Kontextbeschreibung kann jedoch die analytische Generalisierbarkeit gestärkt werden.
    
- **Technische und ethische Implikationen:** Vor dem Feldeinsatz wird ein technisches Pre‑Testing durchgeführt, um Fehler zu beheben und die Benutzerfreundlichkeit zu prüfen. Ein zentraler Aspekt ist die transparente Kommunikation mit allen Beteiligten und das Einholen informierten Einverständnisses. Datenschutz und Datensicherheit werden gemäß DSGVO gewährleistet. Persönliche Identifizierbarkeit der Lernenden wird durch Pseudonymisierung ausgeschlossen.
    

Abschließend sei betont, dass dieses Forschungsvorhaben gleichermaßen als Lernprojekt für die Bildungspraxis und als Wissensprojekt für die Bildungsforschung zu verstehen ist. Die zu erwartenden Erkenntnisse – insbesondere zu den Gelingensbedingungen einer symbiotischen Feedback‑Schleife – liefern wertvolle Hinweise für die Gestaltung künftiger Lehr‑Lern‑Innovationen.

## 6 Zeit‑ und Arbeitsplan & vorläufige Gliederung

|**Zeitraum**|**Phase des Vorhabens**|**Kernaktivitäten**|**Fokus**|
|---|---|---|---|
|**Jahr 1: Vorbereitung und Exploration (2025/2026)**||||
|Aug–Sep 2025|**A1: Konzeption & Betreuersuche**|Finalisierung des Exposés; Kontaktaufnahme mit potenziellen Gutachter*innen; Einarbeitung von Feedback|Konzeptionell / organisatorisch|
|Okt–Dez 2025|**A2: Theoretische Vertiefung**|Intensive Literaturrecherche zu TAM, CLT, Teacher Data Literacy und Learning Analytics; Erstellung einer kommentierten Bibliographie|Theoretisch|
|Jan–Jul 2026|**A3: DBR‑Zyklus 0 (explorativer Vor‑Test)**|Informeller Test der Plattform‑Alpha im Unterricht (kleine Stichprobe); technisches Debugging; formative Erprobung von Fragebogen und Tagebuch; Entwicklertagebuch führen|Praktisch / explorativ|
|**Jahr 2: Pilotstudie (2026/2027)**||||
|Sommer 2026|**B1: Methodische Vorbereitung**|Finalisierung der Erhebungsinstrumente basierend auf Zyklus 0; Detailplanung der Pilotstudie; Einreichung eines Ethikantrags|Methodisch / konzeptionell|
|Aug–Dez 2026|**B2: DBR‑Zyklus 1 (Pilotstudie – Feldphase)**|Formale Datenerhebung im Unterricht mit Prototyp V1.0; Führen des Forschungstagebuchs; regelmäßige Treffen mit dem Critical Friend|Empirisch (Datenerhebung)|
|Jan 2027|**B3: Datenaufbereitung**|Transkription der Interviews; Aufbereitung der Fragebogendaten und Log‑Files|Organisatorisch|
|Feb–Apr 2027|**B4: Erste Datenanalyse**|Explorative Kodierung der qualitativen Daten; deskriptive Auswertung der quantitativen Daten; vertiefte Literaturrecherche zur Einordnung der Befunde|Analytisch (vorbereitend)|
|**Jahr 3: Hauptstudie und Verschriftlichung (2027/2028)**||||
|Sommer 2027|**C1: Analyse der Pilotstudie**|Vertiefte Auswertung aller Pilotdaten (qualitativ: Feinkodierung, Kategorienbildung; quantitativ: ggf. inferenzstatistische Analysen); Erstellung des Joint Displays und Formulierung der Meta‑Inferenzen; Verschriftlichung des Pilotstudienberichts; Ableitung von Re‑Design‑Anforderungen|Analytisch / Schreibarbeit|
|Aug–Dez 2027|**C2: Re‑Design & Hauptstudie**|Technische Umsetzung der Optimierungen in Plattform V2.0; Vorbereitung und Durchführung des DBR‑Zyklus 2 im Unterricht (erneute Datenerhebung, ggf. mit größerer Stichprobe)|Praktisch / empirisch|
|Jan–Mär 2028|**C3: Auswertung & Vergleich**|Auswertung der Hauptstudien‑Daten; Vergleich der Ergebnisse aus Zyklus 1 und 2; Beginn der Verschriftlichung der Ergebnis‑Kapitel|Analytisch / Schreibarbeit|
|Apr–Jul 2028|**C4: Vertiefte Schreibphase**|Fertigstellung der Ergebnisdarstellung und Diskussion; Ableitung finaler Gestaltungsprinzipien und Implikationen; Gesamtsynthese und Schlussfolgerungen|Schreibarbeit|
|**Ab Sommer 2028: Finalisierung**||||
|Aug–Dez 2028|**D: Abschluss der Dissertation**|Überarbeitung der Kapitel; Lektorat; Vorbereitung der Disputation; Abgabe der Dissertation|Abschluss / Dissemination|
**Vorläufige Gliederung der Dissertation:**

1. **Einleitung**  
    1.1 Problemaufriss: Das Last‑Mile‑Problem der datengestützten Bildung  
    1.2 Forschungslücke: Die symbiotische Feedback‑Schleife  
    1.3 Forschungsfragen und Aufbau der Arbeit
    
2. **Theoretischer Rahmen**  
    2.1 Technologieakzeptanz (TAM)  
    2.2 Professionelle Kompetenz (Teacher Data Literacy)  
    2.3 Kognitive Entlastung (Cognitive Load Theory)  
    2.4 Synthese: Integratives Modell der symbiotischen Feedback‑Schleife
    
3. **Forschungsdesign und Methodik**  
    3.1 Forschungsparadigma: Design‑Based Research  
    3.2 Studiendesign: Konvergentes Mixed‑Methods‑Design  
    3.3 Erhebungsinstrumente und Verfahren (Schüler‑ und Lehrerperspektive)  
    3.4 Datenanalyse und Integrationsstrategie (Joint Display)  
    3.5 Ethische Überlegungen und Limitationen
    
4. **Forschungsartefakt** – Konzeption der KI‑gestützten Lernplattform (Version 1.0)  
    4.1 Didaktisches Design und technische Architektur  
    4.2 Abgeleitete Design‑Hypothesen aus dem theoretischen Rahmen
    
5. **DBR‑Zyklus 1: Ergebnisse der Pilotstudie (Prototyp V1.0)**  
    5.1 Kontext und Ablauf der Intervention  
    5.2 Quantitative Ergebnisse (Schülerperspektive)  
    5.3 Qualitative Ergebnisse (Lehrperspektive)  
    5.4 Integration der Befunde (Joint Display und Meta‑Inferenzen)  
    5.5 Implikationen für das Re‑Design (Übergang zu V2.0)
    
6. **DBR‑Zyklus 2: Ergebnisse der Hauptstudie (Prototyp V2.0)**  
    6.1 Beschreibung des Re‑Designs und veränderte Rahmenbedingungen  
    6.2 Ergebnisse (analog Kap. 5) – Fokus auf Veränderungen gegenüber Zyklus 1  
    6.3 Gesamtschau der Ergebnisse aus beiden Zyklen
    
7. **Diskussion**  
    7.1 Beantwortung der Forschungsfragen  
    7.2 Theoretische Einordnung: Beiträge zum Forschungsdiskurs  
    7.3 Praktische Implikationen für die Gestaltung von Feedback‑Systemen  
    7.4 Limitationen und Vorschläge für zukünftige Forschung
    
8. **Fazit**  
    8.1 Zusammenfassung der zentralen Erkenntnisse  
    8.2 Perspektiven für eine datengestützte Schulpraxis
    

## 7 Literaturverzeichnis

ATLAS.ti (2024): **Triangulation in Mixed Methods**. Leitfaden zur Mixed‑Methods‑Forschung.

Brown, S. A., Massey, A. P., Montoya‑Weiss, M. M. & Burkman, J. R. (2002): _Do I Really Have to? User Acceptance of Mandated Technology._ European Journal of Information Systems, 11(4), 283–295.

Creswell, J. W. & Plano Clark, V. L. (2018): _Designing and Conducting Mixed Methods Research_ (3. Aufl.). Los Angeles: SAGE Publications.

Davis, F. D. (1989): _Perceived Usefulness, Perceived Ease of Use, and User Acceptance of Information Technology._ MIS Quarterly, 13(3), 319–340.

Ifenthaler, D. & Olsen, J. K. (2020): _Teachers’ Needs for Data Literacy and Data Analytics._ In D. Ifenthaler, D.‑K. Mah & J. Y.‑K. Yau (Hrsg.), _Utilizing Learning Analytics to Support Study Success_ (S. 15–33). Springer.

Iraj, H., Fudge, A., Khan, H. J., Eacersall, M. S., Gašević, D. & Pardo, A. (2021): _Narrowing the Feedback Gap: Examining Student Engagement with Personalized and Actionable Feedback Messages._ Journal of Learning Analytics, 8(3), 101–117.

Kaliisa, R., Misiejuk, K., López‑Pernas, S., Khalil, M. & Saqr, M. (2023): _Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic Review of Impact on Students’ Achievement, Motivation, Participation and Attitude._ arXiv Preprint, 2312.15042.

Mandinach, E. B. & Gummer, E. S. (2016): _What Does It Mean for Teachers to Be Data Literate? Laying Out the Skills, Knowledge, and Dispositions._ Teaching and Teacher Education, 60, 366–376.

Masiello, I., Mohseni, Z. A., Palma, F., Nordmark, S. & Augustsson, H. (2024): _A Current Overview of the Use of Learning Analytics Dashboards._ Education Sciences, 14(1), 82.

Mesenhöller, J. & Böhme, K. (2024): _Validierung des Onlinefragebogens zur sozialen Akzeptanz von Eltern und Lehrkräften gegenüber künstlicher Intelligenz in der Schule (SAELKIS) und Überprüfung der Faktorstruktur._ Diagnostica, 70(4), 247–258.

Michos, K., Maag, M., Bremerich‑Vos, A. & Aprea, C. (2023): _Teachers’ Data Literacy for Learning Analytics: A Central Predictor for Digital Data Use._ Computers & Education, 194, 104612.

Papamitsiou, Z., Economides, A., Giannakos, M. & Santos, O. (2021): _Educational Data Literacy: A Systematic Review of Teaching Approaches and Data Use Practices._ Educational Technology Research and Development, 69(3), 1521–1567.

Pozdniakov, A., Aldrin, C. & d’ Almeida, J. O. (2024): _Educational Data Visualization Literacy: Mapping Visualisation Competences to Stakeholder Needs in Learning Analytics Dashboards._ Journal of Learning Analytics, 11(1), 63–87.

Simply Psychology (2024): **Convergent Parallel Mixed‑Methods Design – Definition and Examples.** Online‑Artikel.

Stenhouse, L. (1975) [zit. nach McNiff, 2002]: _The role of the critical friend in action research._ In: J. McNiff (Hrsg.), _Action Research: Principles and Practice_. Routledge.

van Merriënboer, J. J. G. & Sweller, J. (2005): _Cognitive Load Theory and Complex Learning: Recent Developments and Future Directions._ Educational Psychology Review, 17(2), 147–177.

Wang, F. & Hannafin, M. J. (2005): _Design‑based Research and Technology‑enhanced Learning Environments._ Educational Technology Research and Development, 53(4), 5–23.

Younas, A., Maddigan, J., Moazzam, Z., Ali, N. A., Ives, L. & Raza, S. (2025): _Convergent Mixed Methods Research: Insights from a Systematic Review._ BMC Medical Research Methodology, 25(1), 9.
